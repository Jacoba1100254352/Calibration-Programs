Index: Workflow_Programs/Neural_Fit.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch\nfrom sklearn.preprocessing import StandardScaler\n\nfrom Configuration_Variables import *\nfrom Supplemental_Sensor_Graph_Functions import *\n\n\ndef load_and_prepare_data(sensor_num, test_num, bit_resolution, mapping='ADC_vs_N'):\n\t# Load data for the current test\n\tinstron_data = pd.read_csv(get_data_filepath(ALIGNED_INSTRON_DIR, sensor_num, _TEST_NUM=test_num))\n\tarduino_data = pd.read_csv(get_data_filepath(CALIBRATED_ARDUINO_DIR, sensor_num, _TEST_NUM=test_num))\n\t\n\tmin_length = min(len(instron_data), len(arduino_data))\n\tinstron_force = instron_data[\"Force [N]\"].iloc[:min_length].values.reshape(-1, 1)\n\tsensor_adc = arduino_data[f\"ADC{sensor_num}\"].iloc[:min_length].values.reshape(-1, 1)\n\t\n\t# Optional quantization step (if needed)\n\tinstron_force_quantized = quantize_data(instron_force.flatten(), bit_resolution)\n\tsensor_adc_quantized = quantize_data(sensor_adc.flatten(), bit_resolution)\n\t\n\t# Depending on the mapping, set inputs and targets\n\tif mapping == 'ADC_vs_N':\n\t\tinputs = instron_force_quantized.reshape(-1, 1)  # Instron force as input\n\t\ttargets = sensor_adc_quantized.reshape(-1, 1)  # Raw ADC values as targets\n\telif mapping == 'N_vs_N':\n\t\tinputs = sensor_adc_quantized.reshape(-1, 1)  # ADC values as input\n\t\ttargets = instron_force_quantized.reshape(-1, 1)  # Instron force as target\n\telse:\n\t\traise ValueError(\"Invalid mapping type. Use 'ADC_vs_N' or 'N_vs_N'.\")\n\t\n\treturn inputs, targets, instron_force_quantized, sensor_adc_quantized\n\n\ndef train_model_with_hyperparameter_tuning(inputs, targets, bit_resolution, test_num, hyperparams_dict):\n\tfrom sklearn.model_selection import train_test_split\n\timport itertools\n\t\n\t# Unpack hyperparameter lists\n\tunits_list = hyperparams_dict.get('units_list', [64, 128])\n\tlayers_list = hyperparams_dict.get('layers_list', [1, 2])\n\tactivation_list = hyperparams_dict.get('activation_list', ['tanh'])\n\tdropout_rate_list = hyperparams_dict.get('dropout_rate_list', [0.0, 0.1])\n\tl2_reg_list = hyperparams_dict.get('l2_reg_list', [0.0001, 0.001])\n\tlearning_rate_list = hyperparams_dict.get('learning_rate_list', [0.0005, 0.001])\n\tepochs_list = hyperparams_dict.get('epochs_list', [100])\n\tbatch_size_list = hyperparams_dict.get('batch_size_list', [64, 256])\n\t\n\t# Split the data into training and validation sets\n\tX_train, X_val, y_train, y_val = train_test_split(inputs, targets, test_size=0.2, random_state=42)\n\t\n\t# Scale the data\n\tinput_scaler = StandardScaler()\n\toutput_scaler = StandardScaler()\n\tX_train_scaled = input_scaler.fit_transform(X_train)\n\ty_train_scaled = output_scaler.fit_transform(y_train)\n\tX_val_scaled = input_scaler.transform(X_val)\n\ty_val_scaled = output_scaler.transform(y_val)\n\t\n\t# Define the hyperparameter grid\n\thyperparameter_grid = list(itertools.product(\n\t\tunits_list, layers_list, activation_list,\n\t\tdropout_rate_list, l2_reg_list, learning_rate_list,\n\t\tepochs_list, batch_size_list\n\t))\n\t\n\tbest_val_loss = float('inf')\n\tbest_hyperparams = None\n\tbest_model_state = None\n\t\n\tresults_list = []\n\t\n\t# Hyperparameter tuning\n\tfor (units_, layers_, activation_, dropout_rate_, l2_reg_, learning_rate_, epochs_, batch_size_) in hyperparameter_grid:\n\t\tprint(f\"Test {test_num}, Hyperparameters: units={units_}, layers={layers_}, activation={activation_}, dropout_rate={dropout_rate_}, l2_reg={l2_reg_}, learning_rate={learning_rate_}, epochs={epochs_}, batch_size={batch_size_}\")\n\t\t\n\t\t# Initialize the model\n\t\tmodel = QuantizedNN(\n\t\t\tinput_dim=1, units=units_, layers=layers_, activation=activation_, dropout_rate=dropout_rate_,\n\t\t\tweight_bit_width=bit_resolution, act_bit_width=bit_resolution\n\t\t)\n\t\t\n\t\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\t\tmodel.to(device)\n\t\tcriterion = nn.MSELoss()\n\t\toptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate_, weight_decay=l2_reg_)\n\t\t\n\t\t# Convert data to PyTorch tensors for training\n\t\tX_train_tensor = torch.Tensor(X_train_scaled).to(device)\n\t\ty_train_tensor = torch.Tensor(y_train_scaled).to(device)\n\t\tX_val_tensor = torch.Tensor(X_val_scaled).to(device)\n\t\ty_val_tensor = torch.Tensor(y_val_scaled).to(device)\n\t\t\n\t\ttrain_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n\t\ttrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_, shuffle=True)\n\t\t\n\t\t# Train the model\n\t\tfor epoch in range(epochs_):\n\t\t\tmodel.train()\n\t\t\ttotal_loss = 0\n\t\t\tfor x_batch, y_batch in train_dataloader:\n\t\t\t\toptimizer.zero_grad()\n\t\t\t\toutputs = model(x_batch)\n\t\t\t\tloss = criterion(outputs, y_batch)\n\t\t\t\tloss.backward()\n\t\t\t\toptimizer.step()\n\t\t\t\ttotal_loss += loss.item()\n\t\t\n\t\t# Validation\n\t\tmodel.eval()\n\t\twith torch.no_grad():\n\t\t\tval_outputs = model(X_val_tensor)\n\t\t\tval_loss = criterion(val_outputs, y_val_tensor).item()\n\t\t\n\t\t# Save results\n\t\tresults_list.append({\n\t\t\t'units': units_,\n\t\t\t'layers': layers_,\n\t\t\t'activation': activation_,\n\t\t\t'dropout_rate': dropout_rate_,\n\t\t\t'l2_reg': l2_reg_,\n\t\t\t'learning_rate': learning_rate_,\n\t\t\t'epochs': epochs_,\n\t\t\t'batch_size': batch_size_,\n\t\t\t'val_loss': val_loss\n\t\t})\n\t\t\n\t\tif val_loss < best_val_loss:\n\t\t\tbest_val_loss = val_loss\n\t\t\tbest_hyperparams = {\n\t\t\t\t'units': units_,\n\t\t\t\t'layers': layers_,\n\t\t\t\t'activation': activation_,\n\t\t\t\t'dropout_rate': dropout_rate_,\n\t\t\t\t'l2_reg': l2_reg_,\n\t\t\t\t'learning_rate': learning_rate_,\n\t\t\t\t'epochs': epochs_,\n\t\t\t\t'batch_size': batch_size_\n\t\t\t}\n\t\t\tbest_model_state = model.state_dict()\n\t\n\t# Retrain the best model on the full dataset\n\tmodel = QuantizedNN(\n\t\tinput_dim=1, units=best_hyperparams['units'], layers=best_hyperparams['layers'],\n\t\tactivation=best_hyperparams['activation'], dropout_rate=best_hyperparams['dropout_rate'],\n\t\tweight_bit_width=bit_resolution, act_bit_width=bit_resolution\n\t)\n\tmodel.load_state_dict(best_model_state)\n\treturn model, input_scaler, output_scaler, best_hyperparams\n\n\ndef train_model(inputs, targets, units, layers, activation, dropout_rate, l2_reg, learning_rate, epochs, batch_size, bit_resolution):\n\t# Initialize scalers\n\tinput_scaler = StandardScaler()\n\toutput_scaler = StandardScaler()\n\tinputs_scaled = input_scaler.fit_transform(inputs)\n\ttargets_scaled = output_scaler.fit_transform(targets)\n\t\n\t# Initialize and train the quantized neural network\n\tmodel = QuantizedNN(\n\t\tinput_dim=1, units=units, layers=layers, activation=activation, dropout_rate=dropout_rate,\n\t\tweight_bit_width=bit_resolution, act_bit_width=bit_resolution\n\t)\n\t\n\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\tmodel.to(device)\n\tcriterion = nn.MSELoss()\n\toptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n\t\n\t# Convert data to PyTorch tensors for training\n\tinputs_tensor = torch.Tensor(inputs_scaled).to(device)\n\ttargets_tensor = torch.Tensor(targets_scaled).to(device)\n\t\n\tdataset = torch.utils.data.TensorDataset(inputs_tensor, targets_tensor)\n\tdataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\t\n\t# Train the model\n\tfor epoch in range(epochs):\n\t\tmodel.train()\n\t\ttotal_loss = 0\n\t\tfor x_batch, y_batch in dataloader:\n\t\t\toptimizer.zero_grad()\n\t\t\toutputs = model(x_batch)\n\t\t\tloss = criterion(outputs, y_batch)\n\t\t\tloss.backward()\n\t\t\toptimizer.step()\n\t\t\ttotal_loss += loss.item()\n\t\tif (epoch + 1) % 10 == 0:\n\t\t\tprint(f\"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(dataloader):.6f}\")\n\t\n\treturn model, input_scaler, output_scaler\n\n\ndef evaluate_model(model, inputs, instron_force, sensor_adc, input_scaler, output_scaler, mapping):\n\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\tmodel.eval()\n\twith torch.no_grad():\n\t\tinputs_scaled = input_scaler.transform(inputs)\n\t\tinputs_tensor = torch.Tensor(inputs_scaled).to(device)\n\t\toutputs_scaled = model(inputs_tensor).cpu().numpy()\n\t\toutputs = output_scaler.inverse_transform(outputs_scaled)\n\t\n\t# First Graph: Residuals in N (calibrated sensor N - Instron N)\n\tif mapping == 'N_vs_N':\n\t\t# Residuals are calculated as the difference between the calibrated N and Instron N\n\t\tresiduals = outputs.flatten() - instron_force.flatten()\n\t\treturn outputs.flatten(), residuals\n\t\n\t# Second Graph: Residuals in ADC (Instron N - ADC values)\n\telif mapping == 'ADC_vs_N':\n\t\t# Residuals are the difference between the ADC values and the predicted output from the model\n\t\tresiduals = sensor_adc.flatten() - outputs.flatten()\n\t\treturn outputs, residuals\n\n\ndef plot_overlay(overlay_ax, inputs, targets, outputs, test_num, mapping):\n\tif mapping == 'N_vs_N':\n\t\t# Plot calibrated N values (Y) vs Instron N (X)\n\t\tx = targets.flatten()  # Instron N\n\t\ty_pred = outputs.flatten()  # Predicted N (Calibrated)\n\t\txlabel = \"Instron Force [N]\"\n\t\tylabel = \"Calibrated Force [N]\"\n\telif mapping == 'ADC_vs_N':\n\t\t# Plot ADC vs Instron N\n\t\tx = targets.flatten()  # Instron N\n\t\ty_pred = outputs.flatten()  # Predicted ADC\n\t\txlabel = \"Instron Force [N]\"\n\t\tylabel = \"ADC Value\"\n\telse:\n\t\traise ValueError(\"Invalid mapping type. Use 'ADC_vs_N' or 'N_vs_N'.\")\n\t\n\toverlay_ax.plot(x, y_pred, label=f\"Test {test_num} - Neural Fit\", linewidth=2)\n\toverlay_ax.set_xlabel(xlabel)\n\toverlay_ax.set_ylabel(ylabel)\n\toverlay_ax.grid(True)\n\n\ndef plot_residuals(residuals_ax, instron_force, residuals, test_num, mapping):\n\tx = instron_force.flatten()  # Instron Force (N) is the baseline\n\t\n\t# Invert the x-axis to make the direction go from larger to smaller\n\tresiduals_ax.invert_xaxis()\n\t\n\tif mapping == 'N_vs_N':\n\t\t# First graph: Residuals in N vs Instron N\n\t\tresiduals_ax.plot(x, residuals, label=f\"Residuals [N] (Test {test_num})\", linewidth=2)  # (Test {test_num})\n\t\tresiduals_ax.set_xlabel(\"Instron Force [N]\")\n\t\tresiduals_ax.set_ylabel(\"Residuals [N]\")\n\telif mapping == 'ADC_vs_N':\n\t\t# Second graph: Residuals in ADC vs Instron N\n\t\tresiduals_ax.plot(x, residuals, label=f\"Residuals [ADC] (Test {test_num})\", linewidth=2)  # (Test {test_num})\n\t\tresiduals_ax.set_xlabel(\"Instron Force [N]\")\n\t\tresiduals_ax.set_ylabel(\"Residuals [ADC]\")\n\telse:\n\t\traise ValueError(\"Invalid mapping type. Use 'N_vs_N' or 'ADC_vs_N'.\")\n\tresiduals_ax.grid(True)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Workflow_Programs/Neural_Fit.py b/Workflow_Programs/Neural_Fit.py
--- a/Workflow_Programs/Neural_Fit.py	(revision 5ae8c20848b87cd770d30441da1385f31aed0dbe)
+++ b/Workflow_Programs/Neural_Fit.py	(date 1727749022137)
@@ -5,11 +5,12 @@
 from Supplemental_Sensor_Graph_Functions import *
 
 
-def load_and_prepare_data(sensor_num, test_num, bit_resolution, mapping='ADC_vs_N'):
+def load_and_prepare_data(sensor_num, test_num, bit_resolution, mapping='ADC_vs_N', window_size=100):
 	# Load data for the current test
 	instron_data = pd.read_csv(get_data_filepath(ALIGNED_INSTRON_DIR, sensor_num, _TEST_NUM=test_num))
 	arduino_data = pd.read_csv(get_data_filepath(CALIBRATED_ARDUINO_DIR, sensor_num, _TEST_NUM=test_num))
 	
+	# Ensure the two datasets are aligned in length
 	min_length = min(len(instron_data), len(arduino_data))
 	instron_force = instron_data["Force [N]"].iloc[:min_length].values.reshape(-1, 1)
 	sensor_adc = arduino_data[f"ADC{sensor_num}"].iloc[:min_length].values.reshape(-1, 1)
@@ -18,16 +19,27 @@
 	instron_force_quantized = quantize_data(instron_force.flatten(), bit_resolution)
 	sensor_adc_quantized = quantize_data(sensor_adc.flatten(), bit_resolution)
 	
-	# Depending on the mapping, set inputs and targets
-	if mapping == 'ADC_vs_N':
-		inputs = instron_force_quantized.reshape(-1, 1)  # Instron force as input
-		targets = sensor_adc_quantized.reshape(-1, 1)  # Raw ADC values as targets
-	elif mapping == 'N_vs_N':
-		inputs = sensor_adc_quantized.reshape(-1, 1)  # ADC values as input
-		targets = instron_force_quantized.reshape(-1, 1)  # Instron force as target
-	else:
-		raise ValueError("Invalid mapping type. Use 'ADC_vs_N' or 'N_vs_N'.")
+	# Prepare inputs and targets as sequences with the given window size
+	inputs = []
+	targets = []
+	
+	for i in range(len(instron_force_quantized) - window_size):
+		if mapping == 'ADC_vs_N':
+			input_seq = instron_force_quantized[i:i + window_size].reshape(-1, 1)  # Instron force as input
+			target_seq = sensor_adc_quantized[i:i + window_size].reshape(-1, 1)  # ADC values as targets
+		elif mapping == 'N_vs_N':
+			input_seq = sensor_adc_quantized[i:i + window_size].reshape(-1, 1)  # ADC values as input
+			target_seq = instron_force_quantized[i:i + window_size].reshape(-1, 1)  # Instron force as targets
+		else:
+			raise ValueError("Invalid mapping type. Use 'ADC_vs_N' or 'N_vs_N'.")
+		
+		inputs.append(input_seq)
+		targets.append(target_seq)
 	
+	# Convert to numpy arrays for further processing
+	inputs = np.array(inputs)  # Shape: (num_samples, window_size, 1)
+	targets = np.array(targets)  # Shape: (num_samples, window_size, 1)
+	
 	return inputs, targets, instron_force_quantized, sensor_adc_quantized
 
 
@@ -152,8 +164,17 @@
 	# Initialize scalers
 	input_scaler = StandardScaler()
 	output_scaler = StandardScaler()
-	inputs_scaled = input_scaler.fit_transform(inputs)
-	targets_scaled = output_scaler.fit_transform(targets)
+	
+	# Flatten inputs for scaling
+	num_samples, seq_len, num_features = inputs.shape
+	inputs_flat = inputs.reshape(-1, num_features)
+	inputs_scaled_flat = input_scaler.fit_transform(inputs_flat)
+	inputs_scaled = inputs_scaled_flat.reshape(num_samples, seq_len, num_features)
+	
+	# Flatten targets for scaling
+	targets_flat = targets.reshape(-1, 1)
+	targets_scaled_flat = output_scaler.fit_transform(targets_flat)
+	targets_scaled = targets_scaled_flat.reshape(num_samples, seq_len)
 	
 	# Initialize and train the quantized neural network
 	model = QuantizedNN(
@@ -194,18 +215,24 @@
 	device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
 	model.eval()
 	with torch.no_grad():
-		inputs_scaled = input_scaler.transform(inputs)
+		num_samples, seq_len, num_features = inputs.shape
+		inputs_flat = inputs.reshape(-1, num_features)
+		inputs_scaled_flat = input_scaler.transform(inputs_flat)
+		inputs_scaled = inputs_scaled_flat.reshape(num_samples, seq_len, num_features)
 		inputs_tensor = torch.Tensor(inputs_scaled).to(device)
-		outputs_scaled = model(inputs_tensor).cpu().numpy()
-		outputs = output_scaler.inverse_transform(outputs_scaled)
+		outputs_scaled = model(inputs_tensor).cpu().numpy()  # shape: (num_samples, seq_len)
+		outputs_flat = outputs_scaled.reshape(-1, 1)
+		outputs = output_scaler.inverse_transform(outputs_flat)
+		outputs = outputs.reshape(num_samples, seq_len)
 	
 	# First Graph: Residuals in N (calibrated sensor N - Instron N)
 	if mapping == 'N_vs_N':
-		# Residuals are calculated as the difference between the calibrated N and Instron N
-		residuals = outputs.flatten() - instron_force.flatten()
-		return outputs.flatten(), residuals
-	
-	# Second Graph: Residuals in ADC (Instron N - ADC values)
+		# Assuming targets are sequences
+		targets = instron_force  # or the appropriate target sequence
+		residuals = outputs - targets[:outputs.shape[0], :outputs.shape[1]]
+		return outputs.flatten(), residuals.flatten()
+		
+		# Second Graph: Residuals in ADC (Instron N - ADC values)
 	elif mapping == 'ADC_vs_N':
 		# Residuals are the difference between the ADC values and the predicted output from the model
 		residuals = sensor_adc.flatten() - outputs.flatten()
Index: Workflow_Programs/Supplemental_Sensor_Graph_Functions.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import brevitas.nn as qnn\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_model_optimization as tfmot\nimport torch.nn as nn\nfrom brevitas.core.scaling import ScalingImplType\nfrom brevitas.quant import Int8WeightPerTensorFixedPoint\nfrom keras.layers import BatchNormalization, Dense, Dropout\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom keras.utils import plot_model\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom scipy.signal import medfilt, savgol_filter\nfrom scipy.stats import linregress\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\nclass QuantizedNN(nn.Module):\n\tdef __init__(\n\t\tself, input_dim, units=64, layers=2, activation='relu', dropout_rate=0.5,\n\t\tweight_bit_width=8, act_bit_width=8\n\t):\n\t\tsuper(QuantizedNN, self).__init__()\n\t\t\n\t\t# Define activations\n\t\tactivation_functions = {\n\t\t\t'relu': qnn.QuantReLU,\n\t\t\t'tanh': qnn.QuantTanh,\n\t\t\t'sigmoid': qnn.QuantSigmoid,\n\t\t\t'hardtanh': qnn.QuantHardTanh,\n\t\t\t'identity': qnn.QuantIdentity\n\t\t}\n\t\t\n\t\tquant_activation_class = activation_functions.get(activation.lower(), qnn.QuantReLU)\n\t\t\n\t\t# Input layer with automatic quantization scaling\n\t\tself.layers = nn.ModuleList([\n\t\t\tqnn.QuantLinear(\n\t\t\t\tinput_dim, units,\n\t\t\t\tbias=True,\n\t\t\t\tweight_bit_width=weight_bit_width,\n\t\t\t\tweight_quant=Int8WeightPerTensorFixedPoint,\n\t\t\t\tscaling_impl_type=ScalingImplType.STATS\n\t\t\t)\n\t\t])\n\t\tself.activations = nn.ModuleList([quant_activation_class(bit_width=act_bit_width)])\n\t\tself.dropouts = nn.ModuleList([nn.Dropout(dropout_rate)])\n\t\t\n\t\t# Hidden layers\n\t\tfor _ in range(1, layers):\n\t\t\tself.layers.append(\n\t\t\t\tqnn.QuantLinear(\n\t\t\t\t\tunits, units,\n\t\t\t\t\tbias=True,\n\t\t\t\t\tweight_bit_width=weight_bit_width,\n\t\t\t\t\tweight_quant=Int8WeightPerTensorFixedPoint,\n\t\t\t\t\tscaling_impl_type=ScalingImplType.STATS\n\t\t\t\t)\n\t\t\t)\n\t\t\tself.activations.append(quant_activation_class(bit_width=act_bit_width))\n\t\t\tself.dropouts.append(nn.Dropout(dropout_rate))\n\t\t\n\t\t# Output layer\n\t\tself.output_layer = qnn.QuantLinear(\n\t\t\tunits, 1,\n\t\t\tbias=True,\n\t\t\tweight_bit_width=weight_bit_width,\n\t\t\tweight_quant=Int8WeightPerTensorFixedPoint,\n\t\t\tscaling_impl_type=ScalingImplType.STATS\n\t\t)\n\t\n\tdef forward(self, x):\n\t\tfor layer, activation, dropout in zip(self.layers, self.activations, self.dropouts):\n\t\t\tx = layer(x)\n\t\t\tx = activation(x)\n\t\t\tx = dropout(x)\n\t\tx = self.output_layer(x)\n\t\treturn x\n\n\ndef avg(lst):\n\treturn sum(lst) / len(lst)\n\n\ndef difference_polarity(lst1, lst2):\n\treturn (avg(lst1) - avg(lst2)) / abs(avg(lst1) - avg(lst2))\n\n\ndef calculate_line_of_best_fit(x, y, isPolyfit=False, order=1):\n\tif not isPolyfit:\n\t\tslope_avg, intercept_avg, _, _, _ = linregress(x, y)\n\t\tline_of_best_fit = slope_avg * x + intercept_avg\n\telse:\n\t\tcoefficients = np.polyfit(x, y, order)\n\t\tpolynomial = np.poly1d(coefficients)\n\t\tline_of_best_fit = polynomial(x)\n\treturn line_of_best_fit\n\n\n# Function to apply smoothing to residuals\ndef apply_smoothing(residuals, method, window_size, poly_order):\n\t\"\"\"\n\tApply smoothing to the residuals using the specified method.\n\n\tParameters:\n\t- residuals: The residual data to be smoothed.\n\t- method: The smoothing method ('savgol', 'boxcar', 'median', or None).\n\t- window_size: The window size for the smoothing operation.\n\t- poly_order: The polynomial order for Savitzky-Golay filter (only used if method is 'savgol').\n\n\tReturns:\n\t- smoothed_residuals: The smoothed residuals.\n\t\"\"\"\n\tif isinstance(residuals, pd.Series):\n\t\tresiduals = residuals.values.flatten()  # Convert Pandas Series to NumPy array and flatten\n\telse:\n\t\tresiduals = residuals.flatten()  # If it's already a NumPy array, just flatten it\n\t\n\tif method == 'savgol':\n\t\tif window_size is None:\n\t\t\traise ValueError(\"Window size must be specified for Savitzky-Golay smoothing.\")\n\t\tsmoothed_residuals = savgol_filter(residuals, window_length=window_size, polyorder=poly_order)\n\telif method == 'boxcar':\n\t\tif window_size is None:\n\t\t\traise ValueError(\"Window size must be specified for boxcar smoothing.\")\n\t\tsmoothed_residuals = np.convolve(residuals, np.ones(window_size) / window_size, mode='valid')\n\t\tsmoothed_residuals = np.pad(smoothed_residuals, (window_size // 2, window_size // 2), mode='edge')\n\t\tif len(smoothed_residuals) > len(residuals):\n\t\t\tsmoothed_residuals = smoothed_residuals[:len(residuals)]\n\t\telif len(smoothed_residuals) < len(residuals):\n\t\t\tsmoothed_residuals = np.pad(smoothed_residuals, (0, len(residuals) - len(smoothed_residuals)), 'edge')\n\telif method == 'median':\n\t\tif window_size is None:\n\t\t\traise ValueError(\"Window size must be specified for median filtering.\")\n\t\tif window_size % 2 == 0:  # Ensure window_size is odd\n\t\t\twindow_size += 1\n\t\tsmoothed_residuals = medfilt(residuals, kernel_size=window_size)\n\telse:\n\t\tsmoothed_residuals = residuals\n\t\n\treturn smoothed_residuals\n\n\n# Helper function for quantizing data (if using custom bit resolutions for inputs/outputs)\ndef quantize_data(data, bit_resolution):\n\t\"\"\"Quantize the data to the given bit resolution.\"\"\"\n\tmax_val = np.max(np.abs(data))\n\tscale = (2**bit_resolution) - 1\n\tquantized_data = np.round(data / max_val * scale) * max_val / scale\n\treturn quantized_data\n\n\n# Function to build a quantized neural network model\ndef build_quantized_neural_network(input_dim, layers=2, units=64, activation='relu', dropout_rate=0.5, l2_reg=0.01, learning_rate=0.001):\n\t\"\"\"\n\tBuild a neural network with quantization-aware training at 8-bit resolution.\n\t\"\"\"\n\t# Define the basic sequential model\n\tmodel = tf.keras.Sequential()\n\t\n\t# Add input and first layer\n\tmodel.add(tf.keras.layers.InputLayer(input_shape=(input_dim,)))\n\tmodel.add(tf.keras.layers.Dense(units, activation=activation, kernel_regularizer=tf.keras.regularizers.l2(l2_reg)))\n\tmodel.add(tf.keras.layers.Dropout(dropout_rate))\n\t\n\t# Add more layers as needed\n\tfor _ in range(layers - 1):\n\t\tmodel.add(tf.keras.layers.Dense(units, activation=activation, kernel_regularizer=tf.keras.regularizers.l2(l2_reg)))\n\t\tmodel.add(tf.keras.layers.Dropout(dropout_rate))\n\t\n\t# Output layer\n\tmodel.add(tf.keras.layers.Dense(1))  # Output layer for regression\n\t\n\t# Compile the model\n\tmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n\t\n\t# Apply 8-bit quantization-aware training\n\tquant_aware_model = tfmot.quantization.keras.quantize_model(model)\n\t\n\treturn quant_aware_model\n\n\n# Function to build a neural network model\ndef build_neural_network(input_dim, layers=2, units=64, activation='relu', dropout_rate=0.5, l2_reg=0.01, learning_rate=0.001):\n\t\"\"\"\n\tBuild a customizable neural network model with specified parameters.\n\n\tParameters:\n\t- input_dim: Dimension of the input data.\n\t- layers: Number of hidden layers in the neural network.\n\t- units: Number of units in each hidden layer.\n\t- activation: Activation function for hidden layers.\n\t- dropout_rate: Dropout rate for regularization.\n\t- l2_reg: L2 regularization parameter.\n\t- learning_rate: Learning rate for the optimizer.\n\n\tReturns:\n\t- model: Compiled Keras model.\n\t\"\"\"\n\t# Sequential allows for building on/adding layers\n\tmodel = Sequential()\n\t# Fully-Connected or Dense layer, all the neurons are connected to the next/previous layer\n\tmodel.add(Dense(units, input_dim=input_dim, activation=activation, kernel_regularizer=l2(l2_reg)))\n\tmodel.add(Dropout(dropout_rate))  # Dropout layer works by randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.\n\tmodel.add(BatchNormalization())  # Batch normalization works by normalizing the input layer by adjusting and scaling the activations.\n\t\n\t\"\"\"\n\t•\tL1 and L2 Regularization:\n\t\t•\tL2 Regularization (Ridge): Adds a penalty equal to the sum of the squared weights to the loss function (e.g., Dense(units, kernel_regularizer=l2(0.01))).\n\t\t•\tL1 Regularization (Lasso): Adds a penalty equal to the sum of the absolute values of the weights (e.g., Dense(units, kernel_regularizer=l1(0.01))).\n\t\t•\tElastic Net: Combines L1 and L2 regularization.\n\t\"\"\"\n\tfor _ in range(layers - 1):\n\t\tmodel.add(Dense(units, activation=activation, kernel_regularizer=l2(l2_reg)))\n\t\tmodel.add(Dropout(dropout_rate))\n\t\tmodel.add(BatchNormalization())\n\t\n\tmodel.add(Dense(1))  # Output layer for regression\n\tmodel.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n\t\n\treturn model\n\n\ndef get_model_memory_usage(batch_size, model):\n\timport numpy as np\n\t\n\ttry:\n\t\tfrom keras import backend as K\n\texcept:\n\t\tfrom tensorflow.keras import backend as K\n\t\n\tshapes_mem_count = 0\n\tinternal_model_mem_count = 0\n\tfor l in model.layers:\n\t\tlayer_type = l.__class__.__name__\n\t\tif layer_type == 'Model':\n\t\t\tinternal_model_mem_count += get_model_memory_usage(batch_size, l)\n\t\tsingle_layer_mem = 1\n\t\tout_shape = l.output_shape\n\t\tif type(out_shape) is list:\n\t\t\tout_shape = out_shape[0]\n\t\tfor s in out_shape:\n\t\t\tif s is None:\n\t\t\t\tcontinue\n\t\t\tsingle_layer_mem *= s\n\t\tshapes_mem_count += single_layer_mem\n\t\n\ttrainable_count = np.sum([K.count_params(p) for p in model.trainable_weights])\n\tnon_trainable_count = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n\t\n\tnumber_size = 4.0\n\tif K.floatx() == 'float16':\n\t\tnumber_size = 2.0\n\tif K.floatx() == 'float64':\n\t\tnumber_size = 8.0\n\t\n\ttotal_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n\tgbytes = np.round(total_memory / (1024.0**3), 3) + internal_model_mem_count\n\treturn gbytes\n\n\ndef get_bit_resolution(model):\n\ttry:\n\t\tfrom keras import backend as K\n\texcept:\n\t\tfrom tensorflow.keras import backend as K\n\t\n\t# Checking default precision used by Keras backend\n\tfloatx_dtype = K.floatx()  # Returns 'float16', 'float32', or 'float64'\n\tbit_resolution = {'float16': 16, 'float32': 32, 'float64': 64}.get(floatx_dtype, 'Unknown')\n\t\n\tprint(f\"Model uses {bit_resolution}-bit precision for signals (weights, activations).\")\n\t\n\t# If needed, we can also check each layer's dtype individually:\n\tfor layer in model.layers:\n\t\tif hasattr(layer, 'dtype'):\n\t\t\tprint(f\"Layer {layer.name} uses {layer.dtype} precision\")\n\t\n\treturn bit_resolution\n\n\ndef get_quantized_bit_resolution(model):\n\ttry:\n\t\tfrom keras import backend as K\n\texcept:\n\t\tfrom tensorflow.keras import backend as K\n\t\n\tquantized_layers = []\n\t\n\t# Check each layer to determine if it's quantized\n\tfor layer in model.layers:\n\t\tlayer_type = layer.__class__.__name__\n\t\t\n\t\t# Layers commonly used in quantized models\n\t\tif 'Quant' in layer_type or hasattr(layer, 'quantize_config'):\n\t\t\tquantized_layers.append(layer)\n\t\t\tprint(f\"Layer {layer.name} is quantized.\")\n\t\n\tif len(quantized_layers) == 0:\n\t\tprint(\"No quantized layers found in the model.\")\n\t\treturn None\n\t\n\t# Assuming TensorFlow Model Optimization Toolkit or similar library is used\n\tfor layer in quantized_layers:\n\t\t# Example of retrieving bit resolution - this part depends on the exact quantization method\n\t\t# Check for a custom attribute like 'quant_bits' (you may need to adjust this based on your framework)\n\t\tif hasattr(layer, 'quant_bits'):\n\t\t\tprint(f\"Layer {layer.name} uses {layer.quant_bits}-bit precision\")\n\t\telse:\n\t\t\tprint(f\"Layer {layer.name} might use quantization, but bit precision is not directly accessible.\")\n\t\n\treturn quantized_layers\n\n\ndef determine_minimum_bit_resolution(data, precision=None, epsilon=1e-12):\n\t\"\"\"\n\tDetermine the minimum bit resolution required to represent the input data\n\tas precisely as possible.\n\n\tParameters:\n\t- data: NumPy array or list of input data to analyze.\n\t- precision: The required precision (smallest difference between values).\n\t\t\t\t If None, it will be automatically calculated based on data.\n\t- epsilon: A small value to handle floating-point precision issues.\n\n\tReturns:\n\t- A dictionary containing:\n\t\t- minimum_bits: The minimum number of bits required.\n\t\t- dynamic_range: The range of the data.\n\t\t- min_val: The minimum value in the data.\n\t\t- max_val: The maximum value in the data.\n\t\t- precision: The precision used for calculation.\n\t\"\"\"\n\t\n\t# Convert to NumPy array if input is a list\n\tif isinstance(data, list):\n\t\tdata = np.array(data)\n\t\n\t# Ensure data is a floating-point type for precision calculations\n\tdata = data.astype(np.float64)\n\t\n\t# Calculate range\n\tmin_val = np.min(data)\n\tmax_val = np.max(data)\n\tdynamic_range = max_val - min_val\n\t\n\t# Handle case where dynamic range is zero (all values are identical)\n\tif dynamic_range == 0:\n\t\tprint(\"All data points are identical. Minimum bit resolution is 1 bit.\")\n\t\treturn {\n\t\t\t\"minimum_bits\": 1,  # 1 bit is sufficient to represent a single unique value\n\t\t\t\"dynamic_range\": dynamic_range,\n\t\t\t\"min_val\": min_val,\n\t\t\t\"max_val\": max_val,\n\t\t\t\"precision\": 0  # No precision needed\n\t\t}\n\t\n\t# If precision is not provided, calculate it\n\tif precision is None:\n\t\tunique_values = np.unique(data)\n\t\tif len(unique_values) < 2:\n\t\t\t# Only one unique value exists\n\t\t\tprint(\"Only one unique value found in data. Minimum bit resolution is 1 bit.\")\n\t\t\treturn {\n\t\t\t\t\"minimum_bits\": 1,\n\t\t\t\t\"dynamic_range\": dynamic_range,\n\t\t\t\t\"min_val\": min_val,\n\t\t\t\t\"max_val\": max_val,\n\t\t\t\t\"precision\": 0\n\t\t\t}\n\t\t# Calculate the smallest difference between sorted unique values\n\t\tdiffs = np.diff(unique_values)\n\t\tprecision = np.min(diffs)\n\t\tif not np.isfinite(precision) or precision <= 0:\n\t\t\tprint(\"Calculated precision is non-finite or non-positive. Setting precision to epsilon.\")\n\t\t\tprecision = epsilon\n\t\n\t# Ensure precision is positive and finite\n\tif precision <= 0 or not np.isfinite(precision):\n\t\tprint(\"Precision must be positive and finite. Setting precision to epsilon.\")\n\t\tprecision = epsilon\n\t\n\t# Calculate the number of bits required\n\tratio = dynamic_range / precision\n\tif ratio <= 0:\n\t\tprint(\"Dynamic range divided by precision is non-positive. Setting minimum bits to 1.\")\n\t\tminimum_bits = 1\n\telse:\n\t\tlog_ratio = np.log2(ratio)\n\t\tif not np.isfinite(log_ratio):\n\t\t\tprint(\"Logarithm of ratio is non-finite. Setting minimum bits to 1.\")\n\t\t\tminimum_bits = 1\n\t\telse:\n\t\t\tminimum_bits = int(np.ceil(log_ratio))\n\t\n\treturn {\n\t\t\"minimum_bits\": minimum_bits,\n\t\t\"dynamic_range\": dynamic_range,\n\t\t\"min_val\": min_val,\n\t\t\"max_val\": max_val,\n\t\t\"precision\": precision\n\t}\n\n\n# Example usage of hyperparameter tuning with RandomizedSearchCV\ndef hyperparameter_tuning(X_train, y_train, input_dim):\n\tmodel = KerasRegressor(build_fn=build_neural_network, input_dim=input_dim, verbose=0)\n\t\n\tparam_dist = {\n\t\t'layers': [1, 2, 3],\n\t\t'units': [32, 64, 128],\n\t\t'activation': ['relu', 'tanh'],  # 'sigmoid'\n\t\t'dropout_rate': [0.2, 0.5, 0.7],\n\t\t'l2_reg': [0.01, 0.001, 0.0001],\n\t\t'learning_rate': [0.01, 0.001, 0.0001],\n\t\t'batch_size': [16, 32, 64, 128, 256],\n\t\t'epochs': [50, 100, 200]\n\t}\n\t\n\trandom_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=20, cv=3, verbose=2, scoring=make_scorer(mean_squared_error, greater_is_better=False))\n\t\n\trandom_search_result = random_search.fit(X_train, y_train)\n\t\n\t# Create a DataFrame to store all results\n\tresults_df = pd.DataFrame(random_search_result.cv_results_)\n\t\n\t# Extract relevant columns and sort by rank_test_score\n\tresults_df = results_df[['params', 'mean_test_score', 'rank_test_score']]\n\tsorted_results = results_df.sort_values(by='rank_test_score')\n\t\n\t# Display all sorted results\n\tprint(\"All Sorted Results:\")\n\tprint(sorted_results)\n\t\n\t# Display the best parameters and score\n\tprint(\"\\nBest Parameters:\", random_search_result.best_params_)\n\tprint(\"Best Score:\", random_search_result.best_score_)\n\t\n\treturn random_search_result.best_estimator_\n\n\ndef display_info(batch_size, model):\n\tmodel.summary(expand_nested=True, show_trainable=True)\n\tmodel_memory = get_model_memory_usage(batch_size, model)\n\tbit_resolution = get_bit_resolution(model)\n\tquantized_layers = get_quantized_bit_resolution(model)\n\tprint(f\"Total model memory usage: {model_memory} GB\")\n\tprint(f\"Bit resolution: {bit_resolution} bits\")\n\tprint(f\"Quantized layers: {quantized_layers}\")\n\t\n\t# Print the weights for each layer\n\tprint(\"Model Weights:\")\n\tfor layer in model.layers:\n\t\tweights = layer.get_weights()\n\t\t\n\t\tif len(weights) > 0:\n\t\t\tprint(f\"Layer: {layer.name}\")\n\t\t\t# Different layers have different numbers of components\n\t\t\tif isinstance(layer, tf.keras.layers.BatchNormalization):\n\t\t\t\tgamma, beta, moving_mean, moving_variance = weights\n\t\t\t\tprint(\"Gamma (scale):\", gamma)\n\t\t\t\tprint(\"Beta (shift):\", beta)\n\t\t\t\tprint(\"Moving Mean:\", moving_mean)\n\t\t\t\tprint(\"Moving Variance:\", moving_variance)\n\t\t\telif len(weights) == 2:  # Dense layers have weights and biases\n\t\t\t\tweights, biases = weights\n\t\t\t\tprint(\"Weights:\", weights)\n\t\t\t\tprint(\"Biases:\", biases)\n\t\t\tprint(\"-\" * 50)\n\n\ndef display_layer_info(model):\n\t# Create a plot of the model architecture\n\tplot_model(model, to_file=\"model_visual.png\", show_shapes=True, show_layer_names=True)\n\t\n\t# Display the generated plot\n\timg = plt.imread(\"model_visual.png\")\n\tplt.figure(figsize=(10, 10))\n\tplt.imshow(img)\n\tplt.axis('off')\n\tplt.show()\n\n\ndef calculate_bit_resolution(data_title, data):\n\t# Determine minimum bit resolution for the data\n\tprint(data_title + \":\")\n\tresult = determine_minimum_bit_resolution(data)\n\tprint(f\"Minimum Bit Resolution: {result['minimum_bits']} bits\")\n\tprint(f\"Dynamic Range: {result['dynamic_range']}\")\n\tprint(f\"Minimum Value: {result['min_val']}\")\n\tprint(f\"Maximum Value: {result['max_val']}\")\n\tprint(f\"Precision: {result['precision']}\")\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Workflow_Programs/Supplemental_Sensor_Graph_Functions.py b/Workflow_Programs/Supplemental_Sensor_Graph_Functions.py
--- a/Workflow_Programs/Supplemental_Sensor_Graph_Functions.py	(revision 5ae8c20848b87cd770d30441da1385f31aed0dbe)
+++ b/Workflow_Programs/Supplemental_Sensor_Graph_Functions.py	(date 1727749081797)
@@ -22,64 +22,53 @@
 class QuantizedNN(nn.Module):
 	def __init__(
 		self, input_dim, units=64, layers=2, activation='relu', dropout_rate=0.5,
-		weight_bit_width=8, act_bit_width=8
+		weight_bit_width=8, act_bit_width=8, rnn_type='LSTM'
 	):
 		super(QuantizedNN, self).__init__()
 		
-		# Define activations
+		# Define activation functions
 		activation_functions = {
-			'relu': qnn.QuantReLU,
-			'tanh': qnn.QuantTanh,
-			'sigmoid': qnn.QuantSigmoid,
-			'hardtanh': qnn.QuantHardTanh,
-			'identity': qnn.QuantIdentity
+			'relu': nn.ReLU,
+			'tanh': nn.Tanh,
+			'sigmoid': nn.Sigmoid,
+			'hardtanh': nn.Hardtanh,
+			'identity': nn.Identity
 		}
-		
-		quant_activation_class = activation_functions.get(activation.lower(), qnn.QuantReLU)
+		activation_class = activation_functions.get(activation.lower(), nn.ReLU)
 		
-		# Input layer with automatic quantization scaling
-		self.layers = nn.ModuleList([
-			qnn.QuantLinear(
-				input_dim, units,
-				bias=True,
-				weight_bit_width=weight_bit_width,
-				weight_quant=Int8WeightPerTensorFixedPoint,
-				scaling_impl_type=ScalingImplType.STATS
+		# Choose between LSTM or GRU layers
+		self.rnn_type = rnn_type
+		if self.rnn_type == 'LSTM':
+			self.rnn = nn.LSTM(
+				input_size=input_dim, hidden_size=units, num_layers=layers,
+				batch_first=True, dropout=dropout_rate if layers > 1 else 0
 			)
-		])
-		self.activations = nn.ModuleList([quant_activation_class(bit_width=act_bit_width)])
-		self.dropouts = nn.ModuleList([nn.Dropout(dropout_rate)])
+		elif self.rnn_type == 'GRU':
+			self.rnn = nn.GRU(
+				input_size=input_dim, hidden_size=units, num_layers=layers,
+				batch_first=True, dropout=dropout_rate if layers > 1 else 0
+			)
 		
-		# Hidden layers
-		for _ in range(1, layers):
-			self.layers.append(
-				qnn.QuantLinear(
-					units, units,
-					bias=True,
-					weight_bit_width=weight_bit_width,
-					weight_quant=Int8WeightPerTensorFixedPoint,
-					scaling_impl_type=ScalingImplType.STATS
-				)
-			)
-			self.activations.append(quant_activation_class(bit_width=act_bit_width))
-			self.dropouts.append(nn.Dropout(dropout_rate))
+		# Fully connected output layer
+		self.fc = nn.Linear(units, 1)  # Predicts 1 value per time step
 		
-		# Output layer
-		self.output_layer = qnn.QuantLinear(
-			units, 1,
-			bias=True,
-			weight_bit_width=weight_bit_width,
-			weight_quant=Int8WeightPerTensorFixedPoint,
-			scaling_impl_type=ScalingImplType.STATS
-		)
+		# Optional activation function after the output layer (if needed)
+		self.output_activation = activation_class()
 	
 	def forward(self, x):
-		for layer, activation, dropout in zip(self.layers, self.activations, self.dropouts):
-			x = layer(x)
-			x = activation(x)
-			x = dropout(x)
-		x = self.output_layer(x)
-		return x
+		# LSTM/GRU layer forward pass
+		if self.rnn_type == 'LSTM':
+			out, (hn, cn) = self.rnn(x)
+		elif self.rnn_type == 'GRU':
+			out, hn = self.rnn(x)
+		
+		# Apply the fully connected layer to the output of each time step
+		out = self.fc(out)  # Shape: (batch_size, seq_len, 1)
+		
+		# Optional: Apply activation function to output (e.g., Tanh for outputs between -1 and 1)
+		out = self.output_activation(out)
+		
+		return out.squeeze(-1)  # Return shape: (batch_size, seq_len)
 
 
 def avg(lst):
Index: Workflow_Programs/Sensor_Graphs.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># from matplotlib.backends.backend_pdf import PdfPages\nimport time\n\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom sklearn.metrics import mean_absolute_error\nfrom scipy.io import savemat\n\n# from Configuration_Variables import *\n# from Supplemental_Sensor_Graph_Functions import *\nfrom Neural_Fit import *\n\n\n# Set MATLAB-like appearance\n# Define font sizes\nSIZE_SMALL = 10\nSIZE_DEFAULT = 14\nSIZE_LARGE = 16\n# plt.rc(\"font\", family=\"Roboto\")  # controls default font\nplt.rc(\"font\", weight=\"normal\")  # controls default font\nplt.rc(\"font\", size=SIZE_DEFAULT)  # controls default text sizes\nplt.rc(\"axes\", titlesize=SIZE_LARGE)  # fontsize of the axes title\nplt.rc(\"axes\", labelsize=SIZE_LARGE)  # fontsize of the x and y labels\nplt.rc(\"xtick\", labelsize=SIZE_DEFAULT)  # fontsize of the tick labels\nplt.rc(\"ytick\", labelsize=SIZE_DEFAULT)  # fontsize of the tick labels\n\nseed_value = 42  # Or any other integer\n\n\ndef analyze_and_graph_neural_fit(\n\ttest_range, sensor_num, units=64, layers=2, activation='tanh', dropout_rate=0.5, l2_reg=0.01,\n\tlearning_rate=0.001, epochs=100, batch_size=32, window_size=100, poly_order=None,\n\tsmoothing_method=\"boxcar\", save_graphs=True, show_graphs=True, bit_resolution=12,\n\tenable_hyperparameter_tuning=False, mapping='N_vs_N',\n\thyperparams_dict=None\n):\n\tplt.close('all')\n\t\n\t# Initialize the PDF to save the graphs\n\twith PdfPages(f\"/Users/jacobanderson/Downloads/Neural_Network_Fit_Sensor_Set_{sensor_num}.pdf\") as pdf:\n\t\t# Set up figures and axes for overlay and residuals\n\t\toverlay_fig, overlay_ax = plt.subplots(figsize=(10, 6))\n\t\tresiduals_fig, residuals_ax = plt.subplots(figsize=(10, 6))\n\t\t\n\t\tfor test_num in test_range:\n\t\t\t# Load and prepare data\n\t\t\tinputs, targets, instron_force, sensor_adc = load_and_prepare_data(\n\t\t\t\tsensor_num, test_num, bit_resolution, mapping\n\t\t\t)\n\t\t\t\n\t\t\tif enable_hyperparameter_tuning:\n\t\t\t\t# Train model with hyperparameter tuning\n\t\t\t\tmodel, input_scaler, output_scaler, best_hyperparams = train_model_with_hyperparameter_tuning(\n\t\t\t\t\tinputs, targets, bit_resolution, test_num, hyperparams_dict\n\t\t\t\t)\n\t\t\telse:\n\t\t\t\t# Train model without hyperparameter tuning\n\t\t\t\tmodel, input_scaler, output_scaler = train_model(\n\t\t\t\t\tinputs, targets, units, layers, activation, dropout_rate, l2_reg,\n\t\t\t\t\tlearning_rate, epochs, batch_size, bit_resolution\n\t\t\t\t)\n\t\t\t\n\t\t\t# Evaluate model and calculate residuals\n\t\t\toutputs, residuals = evaluate_model(model, inputs, instron_force, sensor_adc, input_scaler, output_scaler, mapping)\n\t\t\t\n\t\t\t# Calculate MSE and MAE\n\t\t\tmse_nn = mean_squared_error(targets.flatten(), outputs.flatten())\n\t\t\tmae_nn = mean_absolute_error(targets.flatten(), outputs.flatten())\n\t\t\t\n\t\t\t# Print MSE and MAE for each test\n\t\t\tprint(f\"Test {test_num}, Neural Network Fit: MSE={mse_nn:.6f}, MAE={mae_nn:.6f}\")\n\t\t\t\n\t\t\t# Apply smoothing to residuals\n\t\t\tresiduals_smoothed = apply_smoothing(residuals, method=smoothing_method, window_size=window_size, poly_order=poly_order)\n\t\t\t\n\t\t\t# First Graph: Plot calibrated sensor N vs Instron N\n\t\t\toverlay_ax.plot(targets.flatten(), outputs.flatten(), label=f\"Calibrated Sensor [N] (Test {test_num})\", linestyle='--', linewidth=2)\n\t\t\toverlay_ax.plot(targets.flatten(), targets.flatten(), label=f\"Instron [N] (Test {test_num})\", linewidth=2)\n\t\t\t\n\t\t\t# Customize the graph appearance\n\t\t\toverlay_ax.set_xlabel(\"Instron Force [N]\")\n\t\t\toverlay_ax.set_ylabel(\"Calibrated Sensor Force [N]\")\n\t\t\toverlay_ax.set_title(f\"Neural Fit: Sensor vs. Instron Force ({bit_resolution}-bit)\")  # Sensor-Instron Force Relationship with Neural Fit (12-bit)\n\t\t\toverlay_ax.legend(loc=\"upper left\", fontsize=SIZE_SMALL, markerscale=0.8, labelspacing=0.3)\n\t\t\toverlay_ax.grid(True, which='both', linestyle='--', linewidth=0.75)  # Add grid lines\n\t\t\toverlay_ax.invert_xaxis()\n\t\t\toverlay_ax.invert_yaxis()\n\t\t\t\n\t\t\t# Plot residuals with MATLAB-style aesthetics\n\t\t\tresiduals_ax.plot(instron_force.flatten(), residuals_smoothed, label=f\"Residuals [N] (Test {test_num})\", linewidth=2)\n\t\t\tresiduals_ax.set_xlabel(\"Instron Force [N]\")\n\t\t\tresiduals_ax.set_ylabel(\"Residuals [N]\")\n\t\t\tresiduals_ax.set_title(f\"Residuals with {bit_resolution}-bit model\")\n\t\t\tresiduals_ax.legend(loc=\"upper left\", fontsize=SIZE_SMALL, markerscale=0.8, labelspacing=0.3)\n\t\t\tresiduals_ax.grid(True, which='both', linestyle='--', linewidth=0.75)\n\t\t\tresiduals_ax.invert_xaxis()\n\t\t\n\t\t# Save and show graphs\n\t\tif save_graphs:\n\t\t\tpdf.savefig(overlay_fig)\n\t\t\tpdf.savefig(residuals_fig)\n\t\t\n\t\tif show_graphs:\n\t\t\tplt.show()\n\t\t\n\t\tplt.close(overlay_fig)\n\t\tplt.close(residuals_fig)\n\n\ndef analyze_and_graph_calibrated_data_and_fits_single_pdf_combined_multiple_tests(\n\ttest_range, sensor_num, smoothing_method=None, window_size=100, poly_order=None,\n\tsave_graphs=True, show_graphs=True, bit_resolution=12, mapping='N_vs_N'\n):\n\t\"\"\"\n\tAnalyze and visualize residuals and polynomial fits of different orders for each sensor across multiple tests,\n\tcombining all tests in one graph per polynomial order.\n\n\tParameters:\n\t- test_range: A range or list of test numbers to include in the analysis.\n\t- sensor_num: The sensor number to analyze.\n\t- window_size: Window size for the smoothing operation. If None, no smoothing is applied.\n\t- poly_order: Polynomial order for the Savitzky-Golay filter.\n\t- smoothing_method: The smoothing method ('savgol', 'boxcar', or None).\n\t- save_graphs: Boolean flag to save the graphs as a PDF.\n\t- show_graphs: Boolean flag to display the graphs during the process.\n\t- bit_resolution: The bit resolution to quantize the data (default is 12 bits).\n\t- mapping: Defines what to map on the x and y axes. Options are 'N_vs_N' (Calibrated N vs Instron N)\n\t\t\t   or 'ADC_vs_N' (ADC vs Instron N).\n\t\"\"\"\n\t# Replace SENSOR_SET and STARTING_SENSOR with appropriate variables or parameters if needed\n\tSENSOR_SET = \"YourSensorSet\"  # Update with your actual sensor set identifier\n\tSTARTING_SENSOR = sensor_num\n\t\n\twith PdfPages(f\"/Users/jacobanderson/Downloads/Combined_Tests_Polynomial_Sensor_Analysis_Sensor_Set_{SENSOR_SET}_Sensor_{STARTING_SENSOR}.pdf\") as pdf:\n\t\tfor order in range(1, 5):\n\t\t\tplt.figure(figsize=(10, 6))\n\t\t\t\n\t\t\t# Iterate over each test\n\t\t\tfor _TEST_NUM in test_range:\n\t\t\t\t# Load data from CSV files\n\t\t\t\tinstron_data = pd.read_csv(get_data_filepath(ALIGNED_INSTRON_DIR, sensor_num, _TEST_NUM=_TEST_NUM))\n\t\t\t\tupdated_arduino_data = pd.read_csv(get_data_filepath(CALIBRATED_ARDUINO_DIR, sensor_num, _TEST_NUM=_TEST_NUM))\n\t\t\t\t\n\t\t\t\t# Ensure arrays are of equal length for accurate comparison\n\t\t\t\tmin_length = min(len(instron_data), len(updated_arduino_data))\n\t\t\t\tinstron_force = instron_data[\"Force [N]\"].iloc[:min_length]\n\t\t\t\t\n\t\t\t\t# Depending on mapping, choose data for updated_arduino_force and set labels\n\t\t\t\tif mapping == 'N_vs_N':\n\t\t\t\t\t# Use calibrated force data\n\t\t\t\t\tcalibrated_force_column = \"Force [N]\" if SIMPLIFY else f\"Force{sensor_num} [N]\"\n\t\t\t\t\tif calibrated_force_column in updated_arduino_data.columns:\n\t\t\t\t\t\tupdated_arduino_force = updated_arduino_data[calibrated_force_column].iloc[:min_length]\n\t\t\t\t\t\tylabel = \"Residual Force [N]\"\n\t\t\t\t\telse:\n\t\t\t\t\t\tprint(f\"Calibrated force data not found for sensor {sensor_num} in test {_TEST_NUM}.\")\n\t\t\t\t\t\tcontinue  # Skip this test if calibrated data is missing\n\t\t\t\telif mapping == 'ADC_vs_N':\n\t\t\t\t\t# Use raw ADC data\n\t\t\t\t\tadc_column = \"ADC\" if SIMPLIFY else f\"ADC{sensor_num}\"\n\t\t\t\t\tif adc_column in updated_arduino_data.columns:\n\t\t\t\t\t\tupdated_arduino_force = updated_arduino_data[adc_column].iloc[:min_length]\n\t\t\t\t\t\tylabel = \"Residual Force [ADC]\"\n\t\t\t\t\telse:\n\t\t\t\t\t\tprint(f\"ADC data not found for sensor {sensor_num} in test {_TEST_NUM}.\")\n\t\t\t\t\t\tcontinue  # Skip this test if ADC data is missing\n\t\t\t\telse:\n\t\t\t\t\traise ValueError(\"Invalid mapping type. Use 'N_vs_N' or 'ADC_vs_N'.\")\n\t\t\t\t\n\t\t\t\t# Quantize input and output data\n\t\t\t\tinstron_force = quantize_data(instron_force, bit_resolution)\n\t\t\t\tupdated_arduino_force = quantize_data(updated_arduino_force, bit_resolution)\n\t\t\t\t\n\t\t\t\t# Fit the polynomial model\n\t\t\t\tlin_fit = calculate_line_of_best_fit(x=instron_force, y=updated_arduino_force, isPolyfit=True, order=order)\n\t\t\t\tresiduals = updated_arduino_force - lin_fit\n\t\t\t\t\n\t\t\t\t# Calculate MSE and MAE for polynomial fit\n\t\t\t\tmse_poly = mean_squared_error(updated_arduino_force, lin_fit)\n\t\t\t\tmae_poly = mean_absolute_error(updated_arduino_force, lin_fit)\n\t\t\t\t\n\t\t\t\tprint(f\"Test {_TEST_NUM}, Polynomial Fit (Order {order}): MSE={mse_poly:.6f}, MAE={mae_poly:.6f}\")\n\t\t\t\t\n\t\t\t\t# Apply smoothing using the specified method\n\t\t\t\tresiduals_smoothed = apply_smoothing(\n\t\t\t\t\tresiduals, method=smoothing_method, window_size=window_size, poly_order=poly_order\n\t\t\t\t)\n\t\t\t\t\n\t\t\t\t# Plot the smoothed residuals\n\t\t\t\tplt.plot(instron_force[:len(residuals_smoothed)], residuals_smoothed, '-', label=f\"Test {_TEST_NUM}\", linewidth=2)\n\t\t\t\n\t\t\tplt.xlabel(\"Instron Force [N]\")\n\t\t\tplt.ylabel(ylabel)\n\t\t\tplt.legend(loc=\"lower left\")\n\t\t\tplt.title(f\"Residuals for Polynomial Fit (Order {order}) Across Multiple Tests\")\n\t\t\tplt.grid(True)\n\t\t\tplt.gca().invert_xaxis()\n\t\t\t\n\t\t\tif show_graphs:\n\t\t\t\tplt.show()\n\t\t\t\n\t\t\tif save_graphs:\n\t\t\t\tpdf.savefig()\n\t\t\t\n\t\t\tplt.close()\n\n\ndef analyze_and_graph_residuals_and_fits_individual_images(save_graphs=True, useArduinoADC=True):\n\t\"\"\"\n\tAnalyze and export residuals and polynomial fits of different orders for each sensor into .mat files.\n\t\"\"\"\n\tfor sensor_num in SENSORS_RANGE:\n\t\t# Sleep to avoid HTTPS request limit\n\t\ttime.sleep(5)\n\t\t\n\t\t# Load data from CSV files\n\t\tinstron_data = pd.read_csv(get_data_filepath(ALIGNED_INSTRON_DIR, sensor_num))\n\t\tupdated_arduino_data = pd.read_csv(get_data_filepath(CALIBRATED_ARDUINO_DIR, sensor_num))\n\t\t\n\t\t# Extract time, force, and ADC data\n\t\tinstron_time = instron_data[\"Time [s]\"].to_numpy()\n\t\tinstron_force = instron_data[\"Force [N]\"].to_numpy()\n\t\tupdated_arduino_time = updated_arduino_data[\"Time [s]\"].to_numpy()\n\t\tupdated_arduino_force = updated_arduino_data[\"Force [N]\" if SIMPLIFY else f\"Force{sensor_num} [N]\"].to_numpy()\n\t\t\n\t\t# Get Aligned Arduino Data for ADC results to work regardless of SIMPLIFY's value\n\t\taligned_arduino_data = pd.read_csv(get_data_filepath(ALIGNED_ARDUINO_DIR, sensor_num))\n\t\t\n\t\t# Calculate force difference for export if needed\n\t\tdifference = instron_force - updated_arduino_force\n\t\t\n\t\t# Create dictionary for .mat export\n\t\tdata_dict = {\n\t\t\t'instron_time': instron_time,\n\t\t\t'instron_force': instron_force,\n\t\t\t'updated_arduino_time': updated_arduino_time,\n\t\t\t'updated_arduino_force': updated_arduino_force,\n\t\t\t'difference': difference\n\t\t}\n\t\t\n\t\t# Create filename for the .mat file (relevant to the sensor data)\n\t\tfile_name = f\"/Users/jacobanderson/Downloads/Test_{TEST_NUM}_Sensor_{sensor_num}_calibrated_forces.mat\"\n\t\t\n\t\t# Save the data to a .mat file\n\t\tsavemat(file_name, data_dict)\n\t\t\n\t\tprint(f\"Data for Sensor {sensor_num} saved to {file_name}\")\n\t\t\n\t\texit()\n\t\t\n\t\t# Ensure arrays are of equal length for accurate comparison\n\t\tmin_length = min(len(instron_data), len(updated_arduino_data))\n\t\tinstron_force = instron_data[\"Force [N]\"].iloc[:min_length]\n\t\tif useArduinoADC:\n\t\t\tarduino_force_type = \"ADC\" if SIMPLIFY else f\"ADC{sensor_num}\"\n\t\t\tarduino_force = aligned_arduino_data[\"ADC\" if SIMPLIFY else f\"ADC{sensor_num}\"].iloc[:min_length]\n\t\telse:\n\t\t\tarduino_force_type = \"Force [N]\" if SIMPLIFY else f\"Force{sensor_num} [N]\"\n\t\t\tarduino_force = updated_arduino_force.iloc[:min_length]\n\t\t\n\t\t# Second plot: Relationship between Instron force and Arduino ADC values\n\t\tplt.figure(figsize=(10, 6))\n\t\tplt.scatter(instron_force, arduino_force, label=f\"Instron Force vs. Arduino {arduino_force_type}\", color=\"purple\")\n\t\tplt.xlabel(\"Instron Force [N]\")\n\t\tplt.ylabel(f\"Arduino {arduino_force_type} Values\")\n\t\tplt.legend()\n\t\tplt.title(\n\t\t\tf\"Relationship Between Instron Force and Arduino {arduino_force_type} Values for {SENSOR_SET_DIR}, Sensor {sensor_num}, Test {TEST_NUM}\")\n\t\tplt.grid(True)\n\t\t\n\t\t# Invert the x-axis\n\t\tplt.gca().invert_xaxis()\n\t\t\n\t\tif save_graphs:\n\t\t\tplt.savefig(f\"/Users/jacobanderson/Downloads/Test {TEST_NUM} Sensor {sensor_num} adc against N.png\", dpi=300)\n\t\tplt.show()\n\t\t\n\t\t# Calculate and plot the best-fit line\n\t\tlin_fit = calculate_line_of_best_fit(instron_force, arduino_force)\n\t\t\n\t\t# Plot the best-fit line over the scatter plot\n\t\tplt.figure(figsize=(10, 6))\n\t\tplt.scatter(instron_force, arduino_force, label=\"Actual Data\", color=\"purple\")\n\t\tplt.plot(instron_force, lin_fit, label=\"Best-fit line\", color=\"orange\")\n\t\tplt.xlabel(\"Instron Force [N]\")\n\t\tplt.ylabel(f\"Arduino {arduino_force_type} Values\")\n\t\tplt.legend()\n\t\tplt.title(\n\t\t\tf\"Best-fit Line Through {arduino_force_type} Values for {SENSOR_SET_DIR}, Sensor {sensor_num}, Test {TEST_NUM}\")\n\t\tplt.grid(True)\n\t\t\n\t\t# Invert the x-axis\n\t\tplt.gca().invert_xaxis()\n\t\t\n\t\tif save_graphs:\n\t\t\tplt.savefig(f\"/Users/jacobanderson/Downloads/Test {TEST_NUM} Sensor {sensor_num} best-fit line through {arduino_force_type} values.png\", dpi=300)\n\t\tplt.show()\n\t\t\n\t\t# Calculate and plot residuals\n\t\tresiduals = arduino_force - lin_fit\n\t\tprint(\"Length of residuals:\", len(residuals))\n\t\tplt.figure(figsize=(10, 6))\n\t\tplt.scatter(instron_force, residuals, label=\"Residuals\", color=\"green\")\n\t\t\n\t\t# Calculate a simple moving average of the residuals\n\t\twindow_size = 1000  # Choose a window size that makes sense for your data\n\t\tresiduals_smoothed = np.convolve(residuals, np.ones(window_size) / window_size, mode='valid')\n\t\t\n\t\t# To plot the smoothed residuals, we need to adjust the x-axis (instron_force) due to the convolution operation\n\t\t# This adjustment depends on the 'mode' used in np.convolve. With 'valid', the length of the output is N - K + 1\n\t\tinstron_force_adjusted = instron_force[(window_size - 1):]  # Adjusting the x-axis\n\t\t\n\t\tplt.plot(instron_force_adjusted, residuals_smoothed, label=\"Smoothed Residuals\", color=\"blue\", linewidth=2)\n\t\tplt.axhline(y=0, color='r', linestyle='-')\n\t\tplt.xlabel(\"Instron Force [N]\")\n\t\tplt.ylabel(\"Residuals\")\n\t\tplt.legend()\n\t\tplt.title(\n\t\t\tf\"Smoothed Residuals of {arduino_force_type} Values for {SENSOR_SET_DIR}, Sensor {sensor_num}, Test {TEST_NUM}\")\n\t\tplt.grid(True)\n\t\t\n\t\t# Invert the x-axis\n\t\tplt.gca().invert_xaxis()\n\t\t\n\t\tif save_graphs:\n\t\t\tplt.savefig(f\"/Users/jacobanderson/Downloads/Test {TEST_NUM} Sensor {sensor_num} averaged noise.png\", dpi=300)\n\t\tplt.show()\n\t\t\n\t\t# Fit and plot polynomial models of 1st through 4th order\n\t\tfor order in range(1, 5):\n\t\t\t# Sleep to avoid HTTPS request limit\n\t\t\ttime.sleep(2)\n\t\t\t\n\t\t\t# Fit the polynomial model\n\t\t\tcoefficients = np.polyfit(instron_force, arduino_force, order)\n\t\t\tpolynomial = np.poly1d(coefficients)\n\t\t\tpredicted_adc_force = polynomial(instron_force)\n\t\t\tresiduals = arduino_force - predicted_adc_force\n\t\t\t\n\t\t\t# Smooth the residuals\n\t\t\tresiduals_smoothed = np.convolve(residuals, np.ones(window_size) / window_size, mode='valid')\n\t\t\tinstron_force_adjusted = instron_force[(window_size - 1):]  # Adjusting the x-axis for smoothed residuals\n\t\t\t\n\t\t\tplt.figure(figsize=(10, 6))\n\t\t\tplt.plot(instron_force_adjusted, residuals_smoothed, '-', label=f\"Order {order} smoothed residuals\",\n\t\t\t         linewidth=2)\n\t\t\t\n\t\t\tif order == 1:\n\t\t\t\t# For first-order, you might still want to plot the average line for comparison\n\t\t\t\taverage_residual = np.mean(residuals)\n\t\t\t\tplt.axhline(y=average_residual, color='r', linestyle='-', label=\"Average Residual\")\n\t\t\t\n\t\t\tplt.xlabel(\"Instron Force [N]\")\n\t\t\tplt.ylabel(f\"Arduino {arduino_force_type}\")\n\t\t\tplt.legend()\n\t\t\tplt.title(f\"Smoothed Residuals for Polynomial Fit of Order {order} - Sensor {sensor_num}\")\n\t\t\tplt.grid(True)\n\t\t\t\n\t\t\t# Invert the x-axis\n\t\t\tplt.gca().invert_xaxis()\n\t\t\t\n\t\t\tif save_graphs:\n\t\t\t\tplt.savefig(f\"/Users/jacobanderson/Downloads/Test {TEST_NUM} Sensor {sensor_num} order {order}.png\", dpi=300)\n\t\t\tplt.show()\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Workflow_Programs/Sensor_Graphs.py b/Workflow_Programs/Sensor_Graphs.py
--- a/Workflow_Programs/Sensor_Graphs.py	(revision 5ae8c20848b87cd770d30441da1385f31aed0dbe)
+++ b/Workflow_Programs/Sensor_Graphs.py	(date 1727749022128)
@@ -2,8 +2,8 @@
 import time
 
 from matplotlib.backends.backend_pdf import PdfPages
-from sklearn.metrics import mean_absolute_error
 from scipy.io import savemat
+from sklearn.metrics import mean_absolute_error
 
 # from Configuration_Variables import *
 # from Supplemental_Sensor_Graph_Functions import *
